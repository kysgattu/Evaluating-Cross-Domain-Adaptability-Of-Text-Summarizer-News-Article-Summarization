{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:54:58.268726Z",
     "start_time": "2023-12-05T01:54:58.130508Z"
    }
   },
   "id": "a420193d2b10ad2e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from contractions import contractions_dict\n",
    "def expand_contractions(text, contraction_map=None):\n",
    "    if contraction_map is None:\n",
    "        contraction_map = contractions_dict\n",
    "\n",
    "    # Using regex for getting all contracted words\n",
    "    contractions_keys = '|'.join(re.escape(key) for key in contraction_map.keys())\n",
    "    contractions_pattern = re.compile(f'({contractions_keys})', flags=re.DOTALL)\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(lambda match: contraction_map.get(match.group(0), match.group(0)), text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:54:58.472768Z",
     "start_time": "2023-12-05T01:54:58.461405Z"
    }
   },
   "id": "aa4ec21dc806a71e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "entertainment = pd.read_csv('data/BBCNewsSummaryCSV/entertainment_data.csv') \n",
    "sport = pd.read_csv('data/BBCNewsSummaryCSV/sport_data.csv')\n",
    "tech = pd.read_csv('data/BBCNewsSummaryCSV/tech_data.csv')\n",
    "business = pd.read_csv('data/BBCNewsSummaryCSV/business_data.csv')\n",
    "politics = pd.read_csv('data/BBCNewsSummaryCSV/politics_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:54:58.867437Z",
     "start_time": "2023-12-05T01:54:58.793764Z"
    }
   },
   "id": "457cdc1174a1a615"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "training_dataset = pd.concat([entertainment,sport,tech], ignore_index=True)\n",
    "testing_dataset = pd.concat([business,politics], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:54:59.041362Z",
     "start_time": "2023-12-05T01:54:59.038902Z"
    }
   },
   "id": "4e6f2bd362f9941c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 3894\n",
      "Testing size: 2781\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size:\",training_dataset.size)\n",
    "print(\"Testing size:\",testing_dataset.size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:54:59.300054Z",
     "start_time": "2023-12-05T01:54:59.297100Z"
    }
   },
   "id": "c505d93ece6ccb4f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "training_dataset = training_dataset.sample(frac=1).reset_index(drop=True)\n",
    "testing_dataset = testing_dataset.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:54:59.646610Z",
     "start_time": "2023-12-05T01:54:59.642555Z"
    }
   },
   "id": "60565a31435a3aa1"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "training_dataset['newsarticle'] = training_dataset['newsarticle'].apply(expand_contractions)\n",
    "testing_dataset['newsarticle'] = testing_dataset['newsarticle'].apply(expand_contractions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:03.378146Z",
     "start_time": "2023-12-05T01:55:00.113335Z"
    }
   },
   "id": "9548c7fe9000613a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def getSenLen(sentence):\n",
    "    return len(sentence.split())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:03.386049Z",
     "start_time": "2023-12-05T01:55:03.378671Z"
    }
   },
   "id": "e9bde57dcff61ed4"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "training_dataset['article_length'] = training_dataset['newsarticle'].apply(getSenLen)\n",
    "training_dataset['summary_length'] = training_dataset['summary'].apply(getSenLen)\n",
    "testing_dataset['article_length'] = testing_dataset['newsarticle'].apply(getSenLen)\n",
    "testing_dataset['summary_length'] = testing_dataset['summary'].apply(getSenLen)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:03.423153Z",
     "start_time": "2023-12-05T01:55:03.421525Z"
    }
   },
   "id": "f32b6c40d28d834"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "            filename                                        newsarticle  \\\n0  entertainment_113  Wal-Mart is sued over rude lyrics\\n\\nThe paren...   \n1           tech_304  Format wars could confuse users\\n\\nTechnology ...   \n2  entertainment_087  Global release for Japan hit film\\n\\nOscar-win...   \n3  entertainment_081  Oscars race enters final furlong\\n\\nThe race f...   \n4  entertainment_130  Charity single for quake relief\\n\\nSingers inc...   \n\n                                             summary  article_length  \\\n0  Wal-Mart said it was investigating the claims ...             240   \n1  Instead, said Mr Doctorow, DRM systems were in...             730   \n2  Oscar-winning animator Hayao Miyazaki's latest...             174   \n3  The only people who will know the Oscar winner...             317   \n4  He said the song was a slow ballad and would w...             363   \n\n   summary_length  \n0              98  \n1             312  \n2              64  \n3             139  \n4             135  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>newsarticle</th>\n      <th>summary</th>\n      <th>article_length</th>\n      <th>summary_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>entertainment_113</td>\n      <td>Wal-Mart is sued over rude lyrics\\n\\nThe paren...</td>\n      <td>Wal-Mart said it was investigating the claims ...</td>\n      <td>240</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tech_304</td>\n      <td>Format wars could confuse users\\n\\nTechnology ...</td>\n      <td>Instead, said Mr Doctorow, DRM systems were in...</td>\n      <td>730</td>\n      <td>312</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>entertainment_087</td>\n      <td>Global release for Japan hit film\\n\\nOscar-win...</td>\n      <td>Oscar-winning animator Hayao Miyazaki's latest...</td>\n      <td>174</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>entertainment_081</td>\n      <td>Oscars race enters final furlong\\n\\nThe race f...</td>\n      <td>The only people who will know the Oscar winner...</td>\n      <td>317</td>\n      <td>139</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>entertainment_130</td>\n      <td>Charity single for quake relief\\n\\nSingers inc...</td>\n      <td>He said the song was a slow ballad and would w...</td>\n      <td>363</td>\n      <td>135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:03.431634Z",
     "start_time": "2023-12-05T01:55:03.425793Z"
    }
   },
   "id": "c9c007fed166fe59"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "       article_length  summary_length\ncount     1298.000000     1298.000000\nmean       385.013097      165.270416\nstd        243.616315      109.734916\nmin        115.000000       42.000000\n25%        235.000000       99.250000\n50%        323.000000      137.000000\n75%        465.750000      202.750000\nmax       3540.000000     1706.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_length</th>\n      <th>summary_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1298.000000</td>\n      <td>1298.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>385.013097</td>\n      <td>165.270416</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>243.616315</td>\n      <td>109.734916</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>115.000000</td>\n      <td>42.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>235.000000</td>\n      <td>99.250000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>323.000000</td>\n      <td>137.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>465.750000</td>\n      <td>202.750000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3540.000000</td>\n      <td>1706.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:03.441313Z",
     "start_time": "2023-12-05T01:55:03.430111Z"
    }
   },
   "id": "5d8ad52137f32df0"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Boxplot of Summary Lengths')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a subplot with 1 row and 2 columns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Plot for the articles' number of words\n",
    "sns.boxplot(training_dataset[\"article_length\"], ax=axes[0])\n",
    "axes[0].set_ylabel(\"Number of Words\")\n",
    "axes[0].set_title(\"Boxplot of Article Lengths\")\n",
    "\n",
    "# Plot for the summaries' number of words\n",
    "sns.boxplot(training_dataset[\"summary_length\"], ax=axes[1])\n",
    "axes[1].set_ylabel(\"Number of Words\")\n",
    "axes[1].set_title(\"Boxplot of Summary Lengths\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:03.576547Z",
     "start_time": "2023-12-05T01:55:03.436178Z"
    }
   },
   "id": "bcbd64556a171391"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Get statistics for the articles boxplot\n",
    "lines_articles = axes[0].lines[:6]\n",
    "articles_stats = [line.get_ydata()[0] for line in lines_articles]\n",
    "Q1_articles, Q3_articles, lower_whisker_articles, upper_whisker_articles, median_articles = articles_stats[:5]\n",
    "\n",
    "# Get statistics for the summaries boxplot\n",
    "lines_summaries = axes[1].lines[:6]\n",
    "summaries_stats = [line.get_ydata()[0] for line in lines_summaries]\n",
    "Q1_summaries, Q3_summaries, lower_whisker_summaries, upper_whisker_summaries, median_summaries = summaries_stats[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:03.576671Z",
     "start_time": "2023-12-05T01:55:03.565204Z"
    }
   },
   "id": "3801f4aebe7dd7ee"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810.0\n",
      "355.0\n"
     ]
    }
   ],
   "source": [
    "print(upper_whisker_articles)\n",
    "print(upper_whisker_summaries)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:03.576784Z",
     "start_time": "2023-12-05T01:55:03.567808Z"
    }
   },
   "id": "b7d5711fcca44b34"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "training_dataset = training_dataset[(training_dataset['summary_length'] <= upper_whisker_summaries) & (training_dataset['article_length'] <= upper_whisker_articles)]\n",
    "testing_dataset = testing_dataset[(testing_dataset['summary_length'] <= upper_whisker_summaries) & (testing_dataset['article_length'] <= upper_whisker_articles)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:04.832180Z",
     "start_time": "2023-12-05T01:55:04.828669Z"
    }
   },
   "id": "c7c5ecb8cc3eaf8e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "            filename                                        newsarticle  \\\n0  entertainment_113  Wal-Mart is sued over rude lyrics\\n\\nThe paren...   \n1           tech_304  Format wars could confuse users\\n\\nTechnology ...   \n2  entertainment_087  Global release for Japan hit film\\n\\nOscar-win...   \n3  entertainment_081  Oscars race enters final furlong\\n\\nThe race f...   \n4  entertainment_130  Charity single for quake relief\\n\\nSingers inc...   \n\n                                             summary  article_length  \\\n0  Wal-Mart said it was investigating the claims ...             240   \n1  Instead, said Mr Doctorow, DRM systems were in...             730   \n2  Oscar-winning animator Hayao Miyazaki's latest...             174   \n3  The only people who will know the Oscar winner...             317   \n4  He said the song was a slow ballad and would w...             363   \n\n   summary_length  \n0              98  \n1             312  \n2              64  \n3             139  \n4             135  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>newsarticle</th>\n      <th>summary</th>\n      <th>article_length</th>\n      <th>summary_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>entertainment_113</td>\n      <td>Wal-Mart is sued over rude lyrics\\n\\nThe paren...</td>\n      <td>Wal-Mart said it was investigating the claims ...</td>\n      <td>240</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tech_304</td>\n      <td>Format wars could confuse users\\n\\nTechnology ...</td>\n      <td>Instead, said Mr Doctorow, DRM systems were in...</td>\n      <td>730</td>\n      <td>312</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>entertainment_087</td>\n      <td>Global release for Japan hit film\\n\\nOscar-win...</td>\n      <td>Oscar-winning animator Hayao Miyazaki's latest...</td>\n      <td>174</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>entertainment_081</td>\n      <td>Oscars race enters final furlong\\n\\nThe race f...</td>\n      <td>The only people who will know the Oscar winner...</td>\n      <td>317</td>\n      <td>139</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>entertainment_130</td>\n      <td>Charity single for quake relief\\n\\nSingers inc...</td>\n      <td>He said the song was a slow ballad and would w...</td>\n      <td>363</td>\n      <td>135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:05.914308Z",
     "start_time": "2023-12-05T01:55:05.902555Z"
    }
   },
   "id": "983e13e21d59d9fe"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "       article_length  summary_length\ncount     1240.000000     1240.000000\nmean       351.926613      150.501613\nstd        156.300192       67.456332\nmin        115.000000       42.000000\n25%        233.000000       97.000000\n50%        315.000000      133.500000\n75%        441.000000      190.000000\nmax        810.000000      354.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_length</th>\n      <th>summary_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1240.000000</td>\n      <td>1240.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>351.926613</td>\n      <td>150.501613</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>156.300192</td>\n      <td>67.456332</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>115.000000</td>\n      <td>42.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>233.000000</td>\n      <td>97.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>315.000000</td>\n      <td>133.500000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>441.000000</td>\n      <td>190.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>810.000000</td>\n      <td>354.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:08.349817Z",
     "start_time": "2023-12-05T01:55:08.333192Z"
    }
   },
   "id": "a0f11429d08e49e2"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df = training_dataset[1:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:09.011425Z",
     "start_time": "2023-12-05T01:55:09.007869Z"
    }
   },
   "id": "9878ff524ea2d080"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.utils import clip_grad_norm_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:11.476898Z",
     "start_time": "2023-12-05T01:55:09.410341Z"
    }
   },
   "id": "e2a00a869529e096"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Define the device for GPU usage (if available)\n",
    "if torch.backends.mps.is_available():\n",
    "    arch = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    arch = \"cuda\"\n",
    "else:\n",
    "    arch = \"cpu\"\n",
    "\n",
    "device = torch.device(arch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:47.030176Z",
     "start_time": "2023-12-05T01:55:47.028445Z"
    }
   },
   "id": "157bdbee3912af55"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Tokenize and preprocess the text data\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "max_length = 512  # Maximum sequence length\n",
    "\n",
    "def tokenize_text(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "    return inputs.to(device)  # Move the tokenized inputs to the GPU\n",
    "\n",
    "def tokenize_summary(text):\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=280, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "    return inputs.to(device)  # Move the tokenized summaries to the GPU\n",
    "\n",
    "def tokenize_and_stack(df, text_column, summary_column):\n",
    "    df['TokenizedText'] = df[text_column].apply(tokenize_text)\n",
    "    df['TokenizedSummary'] = df[summary_column].apply(tokenize_summary)\n",
    "    \n",
    "    # Convert tokenized data to PyTorch tensors\n",
    "    X = torch.stack([seq.squeeze() for seq in df['TokenizedText']])\n",
    "    Y = torch.stack([seq.squeeze() for seq in df['TokenizedSummary']])\n",
    "    \n",
    "    # Define a DataLoader for batching data\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "    \n",
    "    return X, Y, dataloader\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize and stack for training set\n",
    "X_train, Y_train, train_dataloader = tokenize_and_stack(train_df, 'newsarticle', 'summary')\n",
    "\n",
    "# Tokenize and stack for validation set\n",
    "X_val, Y_val, val_dataloader = tokenize_and_stack(val_df, 'newsarticle', 'summary')\n",
    "\n",
    "# Tokenize and stack for validation set\n",
    "X_test, Y_test, test_dataloader = tokenize_and_stack(testing_dataset, 'newsarticle', 'summary')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:55:50.669991Z",
     "start_time": "2023-12-05T01:55:47.442931Z"
    }
   },
   "id": "3de94ec11fff3a4f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Tokenize and preprocess the text data\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "max_length = 512  # Maximum sequence length\n",
    "\n",
    "def tokenize_text(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "    return inputs.to(device)  # Move the tokenized inputs to the GPU\n",
    "\n",
    "def tokenize_summary(text):\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=280, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "    return inputs.to(device)  # Move the tokenized summaries to the GPU\n",
    "\n",
    "\n",
    "df['TokenizedText'] = df['newsarticle'].apply(tokenize_text)\n",
    "df['TokenizedSummary'] = df['summary'].apply(tokenize_summary)\n",
    "\n",
    "# Split your data into train and test sets\n",
    "train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert tokenized data to PyTorch tensors\n",
    "X_train = torch.stack([seq.squeeze() for seq in train_df['TokenizedText']])\n",
    "Y_train = torch.stack([seq.squeeze() for seq in train_df['TokenizedSummary']])\n",
    "X_val = torch.stack([seq.squeeze() for seq in eval_df['TokenizedText']])\n",
    "Y_val = torch.stack([seq.squeeze() for seq in eval_df['TokenizedSummary']])\n",
    "\n",
    "# Define a DataLoader for batching data\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e5dca6c2b35b0c4"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kysgattu/anaconda3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:124: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the BART model\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "\n",
    "# Create a GradScaler for mixed-precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Define hyperparameters\n",
    "model.to(device)  # Move the model to the GPU\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)  \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=50, num_training_steps=len(train_dataloader) * 10)  # Add learning rate scheduler\n",
    "early_stopping_rounds = 2\n",
    "best_rouge_score = -1\n",
    "current_round = 0\n",
    "\n",
    "# Define gradient accumulation steps\n",
    "accumulation_steps = 20  # You can adjust this number\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T21:56:42.146924Z",
     "start_time": "2023-12-04T21:56:39.027567Z"
    }
   },
   "id": "ac3e3385893115dc"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
    "        inputs = batch[0].to(device)  # Move the input batch to the GPU\n",
    "        attention_mask = (inputs != 0).float().to(device)  # Create attention mask\n",
    "        targets = batch[1].to(device)  # Move the target batch to the GPU\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(input_ids=inputs, attention_mask=attention_mask, decoder_input_ids=targets, labels=targets)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        # Perform gradient accumulation\n",
    "        loss = loss / accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            # Update gradients and optimizer once every accumulation_steps\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)  # Optional gradient clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T21:57:32.326102Z",
     "start_time": "2023-12-04T21:57:32.307419Z"
    }
   },
   "id": "199a2d170dc530ce"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/20 [00:00<?, ?it/s]/Users/kysgattu/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 20/20 [00:18<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Train Loss: 0.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:15<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Train Loss: 0.6501\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(2):  # Change the number of epochs as needed\n",
    "    train_loss = train(model, train_dataloader, optimizer, scheduler)\n",
    "    print(f\"Epoch {epoch+1}/{2}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "model.save_pretrained(\"saved_model\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T21:58:12.966214Z",
     "start_time": "2023-12-04T21:57:38.066095Z"
    }
   },
   "id": "227221be2f15ac78"
  },
  {
   "cell_type": "markdown",
   "source": [
    "def calculate_rouge1_precision(logits, targets):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    rouge1_precision = 0.0\n",
    "    num_samples = len(logits)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        predicted_ids = logits[i].cpu().numpy()\n",
    "        target_ids = targets[i].cpu().numpy()\n",
    "\n",
    "        # Convert token IDs to strings\n",
    "        predicted_text = tokenizer.decode(predicted_ids, skip_special_tokens=True)\n",
    "        target_text = tokenizer.decode(target_ids, skip_special_tokens=True)\n",
    "\n",
    "        # Calculate ROUGE-1 precision\n",
    "        scores = scorer.score(predicted_text, target_text)\n",
    "        rouge1_precision += scores['rouge1'].precision\n",
    "\n",
    "    return rouge1_precision / num_samples\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb9fabfa2a81d5d6"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test:  20%|██        | 1/5 [09:48<39:15, 588.76s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[58], line 33\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m test_articles, actual_summaries, predicted_summaries, rouge1_precision_scores\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m test_articles, actual_summaries, predicted_summaries, rouge1_precision_scores \u001B[38;5;241m=\u001B[39m evaluate(model, test_dataloader)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# Create a dictionary with the extracted data\u001B[39;00m\n\u001B[1;32m     36\u001B[0m data \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mArticle\u001B[39m\u001B[38;5;124m'\u001B[39m: test_articles,\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mActual Summary\u001B[39m\u001B[38;5;124m'\u001B[39m: actual_summaries,\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicted Summary\u001B[39m\u001B[38;5;124m'\u001B[39m: predicted_summaries,\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mROUGE-1 Precision\u001B[39m\u001B[38;5;124m'\u001B[39m: rouge1_precision_scores,\n\u001B[1;32m     41\u001B[0m }\n",
      "Cell \u001B[0;32mIn[58], line 16\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(model, dataloader)\u001B[0m\n\u001B[1;32m     14\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m (inputs \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     15\u001B[0m targets \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 16\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(input_ids\u001B[38;5;241m=\u001B[39minputs, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, num_beams\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m17\u001B[39m, length_penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2.0\u001B[39m, early_stopping\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m output, target, input_text \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(outputs, targets, inputs):\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m# Calculate ROUGE-1 precision for each sample\u001B[39;00m\n\u001B[1;32m     20\u001B[0m     output_text \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(output, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1675\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1668\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   1669\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1670\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   1671\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   1672\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1673\u001B[0m     )\n\u001B[1;32m   1674\u001B[0m     \u001B[38;5;66;03m# 13. run beam search\u001B[39;00m\n\u001B[0;32m-> 1675\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeam_search(\n\u001B[1;32m   1676\u001B[0m         input_ids,\n\u001B[1;32m   1677\u001B[0m         beam_scorer,\n\u001B[1;32m   1678\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mlogits_processor,\n\u001B[1;32m   1679\u001B[0m         stopping_criteria\u001B[38;5;241m=\u001B[39mstopping_criteria,\n\u001B[1;32m   1680\u001B[0m         pad_token_id\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mpad_token_id,\n\u001B[1;32m   1681\u001B[0m         eos_token_id\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39meos_token_id,\n\u001B[1;32m   1682\u001B[0m         output_scores\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39moutput_scores,\n\u001B[1;32m   1683\u001B[0m         return_dict_in_generate\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mreturn_dict_in_generate,\n\u001B[1;32m   1684\u001B[0m         synced_gpus\u001B[38;5;241m=\u001B[39msynced_gpus,\n\u001B[1;32m   1685\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1686\u001B[0m     )\n\u001B[1;32m   1688\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE:\n\u001B[1;32m   1689\u001B[0m     \u001B[38;5;66;03m# 11. prepare logits warper\u001B[39;00m\n\u001B[1;32m   1690\u001B[0m     logits_warper \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_logits_warper(generation_config)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:3030\u001B[0m, in \u001B[0;36mGenerationMixin.beam_search\u001B[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001B[0m\n\u001B[1;32m   3025\u001B[0m next_token_logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :]\n\u001B[1;32m   3026\u001B[0m next_token_scores \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mlog_softmax(\n\u001B[1;32m   3027\u001B[0m     next_token_logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   3028\u001B[0m )  \u001B[38;5;66;03m# (batch_size * num_beams, vocab_size)\u001B[39;00m\n\u001B[0;32m-> 3030\u001B[0m next_token_scores_processed \u001B[38;5;241m=\u001B[39m logits_processor(input_ids, next_token_scores)\n\u001B[1;32m   3031\u001B[0m next_token_scores \u001B[38;5;241m=\u001B[39m next_token_scores_processed \u001B[38;5;241m+\u001B[39m beam_scores[:, \u001B[38;5;28;01mNone\u001B[39;00m]\u001B[38;5;241m.\u001B[39mexpand_as(next_token_scores)\n\u001B[1;32m   3033\u001B[0m \u001B[38;5;66;03m# Store scores, attentions and hidden_states when required\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/generation/logits_process.py:97\u001B[0m, in \u001B[0;36mLogitsProcessorList.__call__\u001B[0;34m(self, input_ids, scores, **kwargs)\u001B[0m\n\u001B[1;32m     95\u001B[0m         scores \u001B[38;5;241m=\u001B[39m processor(input_ids, scores, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 97\u001B[0m         scores \u001B[38;5;241m=\u001B[39m processor(input_ids, scores)\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scores\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/generation/logits_process.py:765\u001B[0m, in \u001B[0;36mNoRepeatNGramLogitsProcessor.__call__\u001B[0;34m(self, input_ids, scores)\u001B[0m\n\u001B[1;32m    763\u001B[0m num_batch_hypotheses \u001B[38;5;241m=\u001B[39m scores\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    764\u001B[0m cur_len \u001B[38;5;241m=\u001B[39m input_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m--> 765\u001B[0m banned_batch_tokens \u001B[38;5;241m=\u001B[39m _calc_banned_ngram_tokens(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mngram_size, input_ids, num_batch_hypotheses, cur_len)\n\u001B[1;32m    766\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, banned_tokens \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(banned_batch_tokens):\n\u001B[1;32m    767\u001B[0m     scores[i, banned_tokens] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/generation/logits_process.py:707\u001B[0m, in \u001B[0;36m_calc_banned_ngram_tokens\u001B[0;34m(ngram_size, prev_input_ids, num_hypos, cur_len)\u001B[0m\n\u001B[1;32m    704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cur_len \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m<\u001B[39m ngram_size:\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;66;03m# return no banned tokens if we haven't generated no_repeat_ngram_size tokens yet\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [[] \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_hypos)]\n\u001B[0;32m--> 707\u001B[0m generated_ngrams \u001B[38;5;241m=\u001B[39m _get_ngrams(ngram_size, prev_input_ids, num_hypos)\n\u001B[1;32m    708\u001B[0m banned_tokens \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    709\u001B[0m     _get_generated_ngrams(generated_ngrams[hypo_idx], prev_input_ids[hypo_idx], ngram_size, cur_len)\n\u001B[1;32m    710\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hypo_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_hypos)\n\u001B[1;32m    711\u001B[0m ]\n\u001B[1;32m    712\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m banned_tokens\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/generation/logits_process.py:668\u001B[0m, in \u001B[0;36m_get_ngrams\u001B[0;34m(ngram_size, prev_input_ids, num_hypos)\u001B[0m\n\u001B[1;32m    666\u001B[0m generated_ngrams \u001B[38;5;241m=\u001B[39m [{} \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_hypos)]\n\u001B[1;32m    667\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_hypos):\n\u001B[0;32m--> 668\u001B[0m     gen_tokens \u001B[38;5;241m=\u001B[39m prev_input_ids[idx]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m    669\u001B[0m     generated_ngram \u001B[38;5;241m=\u001B[39m generated_ngrams[idx]\n\u001B[1;32m    670\u001B[0m     \u001B[38;5;66;03m# Loop through each n-gram of size ngram_size in the list of tokens (gen_tokens)\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_articles = []\n",
    "    actual_summaries = []\n",
    "    predicted_summaries = []\n",
    "    rouge1_precision_scores = []\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating Test\"):\n",
    "            inputs = batch[0].to(device)\n",
    "            attention_mask = (inputs != 0).float().to(device)\n",
    "            targets = batch[1].to(device)\n",
    "            outputs = model.generate(input_ids=inputs, attention_mask=attention_mask, max_length=150, num_beams=17, length_penalty=2.0, early_stopping=False)\n",
    "            \n",
    "            for output, target, input_text in zip(outputs, targets, inputs):\n",
    "                # Calculate ROUGE-1 precision for each sample\n",
    "                output_text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "                target_text = tokenizer.decode(target, skip_special_tokens=True)\n",
    "                rouge_scores = scorer.score(output_text, target_text)\n",
    "                rouge1_precision_scores.append(rouge_scores['rouge1'].precision)\n",
    "                \n",
    "                # Append tokenized text, actual summaries, and predicted summaries\n",
    "                test_articles.append(tokenizer.decode(input_text, skip_special_tokens=True))\n",
    "                actual_summaries.append(target_text)\n",
    "                predicted_summaries.append(output_text)\n",
    "\n",
    "    return test_articles, actual_summaries, predicted_summaries, rouge1_precision_scores\n",
    "\n",
    "# Evaluate the model\n",
    "test_articles, actual_summaries, predicted_summaries, rouge1_precision_scores = evaluate(model, val_dataloader)\n",
    "\n",
    "# Create a dictionary with the extracted data\n",
    "data = {\n",
    "    'Article': test_articles,\n",
    "    'Actual Summary': actual_summaries,\n",
    "    'Predicted Summary': predicted_summaries,\n",
    "    'ROUGE-1 Precision': rouge1_precision_scores,\n",
    "}\n",
    "\n",
    "# Create a Pandas DataFrame from the dictionary\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "results_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:31:14.018743Z",
     "start_time": "2023-12-04T20:21:23.669312Z"
    }
   },
   "id": "ad142b7728d4c98a"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "'summarize: Hotspot users gain free net calls\\n\\nPeople using wireless net hotspots will soon be able to make free phone calls as well as surf the net.\\n\\nWireless provider Broadreach and net telephony firm Skype are rolling out a service at 350 hotspots around the UK this week. Users will need a Skype account - downloadable for free - and they will then be able to make net calls via wi-fi without paying for net access. Skype allows people to make free PC-based calls to other Skype users.\\n\\nUsers of the system can also make calls to landlines and mobiles for a fee. The system is gaining in popularity and now has 28 million users around the world. Its paid service - dubbed Skype Out - has so far attracted 940,000 users. It plans to add more paid services with forthcoming launches of video conferencing, voice mail and Skype In, a service which would allow users to receive phone calls from landlines and mobiles. London-based software developer Connectotel has unveiled software that will expand the SMS functions of Skype, allowing users to send text messages to mobile phones from the service. Broadreach Networks has around two million users and hotspots in places such as Virgin Megastores, the Travelodge chain of hotels and all Londons major rail terminals. The company is due to launch wi-fi on Virgin Trains later in the year. \"Skypes success at spreading the world about internet telephony is well-known and we are delighted to be offering free access to Skype users in our hotspots,\" commented Broadreach chief executive Magnus McEwen-King.\\n'"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Article'][1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:20:38.888479Z",
     "start_time": "2023-12-04T20:20:38.871567Z"
    }
   },
   "id": "91c7d4810c3fafcc"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "602"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_df['Actual Summary'][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:21:15.064962Z",
     "start_time": "2023-12-04T20:21:15.047970Z"
    }
   },
   "id": "c166677bcb78059d"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "'summarize: Hotspot users gain free net calls to other Skype users. Players of the system can also make $$$$ as well as surf the net with a $1,000, $2, $3, $4, $5, $6, $7, $8, $10, $11, $9, $12, $1 and $24, $16, $25 and net telephony firm Skype are rolling out a service at 350 hotspots around the UK this week. Users will need a Skype account - downloadable for free - and they will then be able to make net calls via wi-fi without paying for net access. Skype allows people to make free PC-based calls to'"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_df['Predicted Summary'][1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:20:07.366510Z",
     "start_time": "2023-12-04T20:20:07.352765Z"
    }
   },
   "id": "a9cb175567a988ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get_ipython().system('jupyter nbconvert --to script BART-Base.ipynb')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f657492f39fd299a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predicted_summaries = []\n",
    "    all_actual_summaries = []\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs = batch[0].to(device)\n",
    "            attention_mask = (inputs != 0).float().to(device)\n",
    "            targets = batch[1].to(device)\n",
    "            outputs = model.generate(input_ids=inputs, attention_mask=attention_mask, max_length=150, num_beams=17, length_penalty=2.0, early_stopping=False)\n",
    "            \n",
    "            for output, target in zip(outputs, targets):\n",
    "                # Convert token IDs to strings\n",
    "                output_text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "                target_text = tokenizer.decode(target, skip_special_tokens=True)\n",
    "\n",
    "                all_predicted_summaries.append(output_text)\n",
    "                all_actual_summaries.append(target_text)\n",
    "\n",
    "    # Calculate ROUGE-1 precision for all predictions\n",
    "    rouge1_precision = calculate_rouge1_precision(all_predicted_summaries, all_actual_summaries)\n",
    "\n",
    "    return rouge1_precision\n",
    "\n",
    "def calculate_rouge1_precision(predictions, targets):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    rouge1_precision = 0.0\n",
    "    num_samples = len(predictions)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        predicted_text = predictions[i]\n",
    "        target_text = targets[i]\n",
    "\n",
    "        scores = scorer.score(predicted_text, target_text)\n",
    "        rouge1_precision += scores['rouge1'].precision\n",
    "\n",
    "    return rouge1_precision / num_samples\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T01:57:20.157093Z",
     "start_time": "2023-12-05T01:57:20.154851Z"
    }
   },
   "id": "7792d5d964ed0cb3"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kysgattu/anaconda3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:124: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/kysgattu/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/20 [00:00<?, ?it/s]/Users/kysgattu/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 20/20 [01:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Train Loss: 0.6416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [02:57<00:00, 35.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, ROUGE-1 Precision: 0.4256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/20 [00:00<?, ?it/s]/Users/kysgattu/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 20/20 [01:06<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Train Loss: 0.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [02:59<00:00, 35.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, ROUGE-1 Precision: 0.4256\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BartForConditionalGeneration, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import networkx as nx\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Assuming you have already defined your train_dataloader, test_dataloader, and other necessary components\n",
    "\n",
    "# Define the BART model\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "\n",
    "# Create a GradScaler for mixed-precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Define hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move the model to the GPU\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)  \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=50, num_training_steps=len(train_dataloader) * 10)  # Add learning rate scheduler\n",
    "early_stopping_rounds = 2\n",
    "best_rouge_score = -1\n",
    "current_round = 0\n",
    "evaluation_interval = 1  # Evaluate every epoch in this example, adjust as needed\n",
    "\n",
    "# Define gradient accumulation steps\n",
    "accumulation_steps = 20  # You can adjust this number\n",
    "\n",
    "# Training loop with continuous evaluation and model saving\n",
    "for epoch in range(2):  # Change the number of epochs as needed\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
    "        inputs = batch[0].to(device)  # Move the input batch to the GPU\n",
    "        attention_mask = (inputs != 0).float().to(device)  # Create attention mask\n",
    "        targets = batch[1].to(device)  # Move the target batch to the GPU\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(input_ids=inputs, attention_mask=attention_mask, decoder_input_ids=targets, labels=targets)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        # Perform gradient accumulation\n",
    "        loss = loss / accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            # Update gradients and optimizer once every accumulation_steps\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)  # Optional gradient clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print average training loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{2}, Train Loss: {total_loss / len(train_dataloader):.4f}\")\n",
    "\n",
    "    # Continuous evaluation at specified intervals\n",
    "    if (epoch + 1) % evaluation_interval == 0:\n",
    "        rouge1_precision = evaluate(model, val_dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{2}, ROUGE-1 Precision: {rouge1_precision:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if rouge1_precision > best_rouge_score:\n",
    "            best_rouge_score = rouge1_precision\n",
    "            current_round = 0\n",
    "            # Save the model checkpoint\n",
    "            model.save_pretrained(\"best_model_checkpoint\")\n",
    "        else:\n",
    "            current_round += 1\n",
    "\n",
    "        # Early stopping logic (if needed)\n",
    "        if current_round >= early_stopping_rounds:\n",
    "            print(\"Early stopping! The model performance is not improving.\")\n",
    "            break\n",
    "\n",
    "# Load the best model for testing\n",
    "best_model = BartForConditionalGeneration.from_pretrained(\"best_model_checkpoint\")\n",
    "# Now you can use this best_model for testing\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T02:05:37.396200Z",
     "start_time": "2023-12-05T01:57:23.518674Z"
    }
   },
   "id": "6a3e414816bca8b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assuming you have already defined your test_dataloader and other necessary components\n",
    "\n",
    "# Load the best model for testing\n",
    "# best_model = BartForConditionalGeneration.from_pretrained(\"best_model_checkpoint\")\n",
    "best_model.to(device)  # Move the model to the GPU if available\n",
    "\n",
    "# Testing function\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predicted_summaries = []\n",
    "    all_actual_summaries = []\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Testing\"):\n",
    "            inputs = batch[0].to(device)\n",
    "            attention_mask = (inputs != 0).float().to(device)\n",
    "            targets = batch[1].to(device)\n",
    "            outputs = model.generate(input_ids=inputs, attention_mask=attention_mask, max_length=150, num_beams=17, length_penalty=2.0, early_stopping=False)\n",
    "            \n",
    "            for output, target in zip(outputs, targets):\n",
    "                # Convert token IDs to strings\n",
    "                output_text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "                target_text = tokenizer.decode(target, skip_special_tokens=True)\n",
    "\n",
    "                all_predicted_summaries.append(output_text)\n",
    "                all_actual_summaries.append(target_text)\n",
    "\n",
    "    # Calculate ROUGE-1 precision for all predictions\n",
    "    rouge1_precision = calculate_rouge1_precision(all_predicted_summaries, all_actual_summaries)\n",
    "\n",
    "    print(f\"ROUGE-1 Precision on Test Set: {rouge1_precision:.4f}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cb9d939974e631d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Call the testing function\n",
    "test(best_model, test_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe6a5f0975ab5558"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def generate_summary(text, loader_model):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=150, truncation=True, padding='max_length', return_attention_mask=True)\n",
    "\n",
    "    # Generate summary using the loaded model\n",
    "    with torch.no_grad():\n",
    "        summary_ids = loaded_model.generate(inputs, max_length=512, num_beams=17, length_penalty=2.0, early_stopping=False)\n",
    "\n",
    "    # Decode the generated summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:07:31.451714Z",
     "start_time": "2023-12-04T20:07:31.442038Z"
    }
   },
   "id": "a014856103ef7e87"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "input_text = training_dataset['newsarticle'][2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:08:03.192283Z",
     "start_time": "2023-12-04T20:08:03.168777Z"
    }
   },
   "id": "a177fa2c9b9d1bd8"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "loaded_model = BartForConditionalGeneration.from_pretrained(\"saved_model\")\n",
    "# tokenizer = BartTokenizer.from_pretrained(\"best_model_checkpoint\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:08:05.900670Z",
     "start_time": "2023-12-04T20:08:03.650704Z"
    }
   },
   "id": "1398ecb253589b33"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "'Zambia confident and cautious\\n\\nZambias technical director, Kalusha Bwalya is confident and cautious ahead of the Cosafa Cup final against Angola on Saturday in Lusaka.\\n\\nBwalya said: \"Nothing short of victory will do.\" However Bwalya warned his side not to be too complacent. \"I do not want my team to be too comfortable or too sure of victory as it is going to be a difficult game. \"For me the main aim of the game is to enjoy and to win.\" Zambia have shown their determination to win this final by recalling nine of their foreign-based players. However the 41 year-old Bwalya, who became the oldest player to appear in the competition when he played and scored against Mauritius, is uncertain whether he will take to the field or not. The Chipolopolo fans however are not being so cautious with a victory concert already scheduled for after the match featuring some of the countrys top musicians. Both sides are hoping to win the competition for a record third time, and so keep the trophy for good. The Chipolopolo won the first two editions of the regional tournament for Southern African nations in 1997 and 1998. They were prevented from a third straight win by Angola who knocked out the Zambians at the semi-final stage in 1999. That victory for Angola also marked a first defeat in 14 years for Zambia at Lusakas Independence stadium, where Saturdays game is being played. Angola named just four overseas-based players in their preliminary squad. The Palancas Negras have been unable to secure the release of many of their Portugal-based players.\\n'"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:08:05.904207Z",
     "start_time": "2023-12-04T20:08:05.902067Z"
    }
   },
   "id": "4e20a99f342d87e7"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "1555"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:08:05.907020Z",
     "start_time": "2023-12-04T20:08:05.904635Z"
    }
   },
   "id": "ce0f235c38566186"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "generated_summary = generate_summary(input_text,loaded_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:08:18.640192Z",
     "start_time": "2023-12-04T20:08:05.908463Z"
    }
   },
   "id": "182aec2f9c42b066"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "735"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_summary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:08:18.643761Z",
     "start_time": "2023-12-04T20:08:18.640850Z"
    }
   },
   "id": "5e3b8b4cfe118a4d"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: summarize: Zambia confident and cautious ahead of Cosafa Cup finalZambias technical director, Kalusha Bwalya says Zambia have nothing short of victory as they prepare to face Angola on Saturday in Lusaka. Zambia will face Angola in the Cosafa World Cup final on Saturday.Zambia's technical directorKALUSA BWALYABWalya said: \"Nothing short of margin of victory will do.\" However Bwalaa warned his side not to be too complacent. \"I do not want my team to betoo comfortable or too sure of victory, as it is going to be a difficult game. \"For me the main aim of the game is to enjoy and to win.\" Zambians have shown their determination to win this final by recalling nine of their foreign-based players. However the 41 year-old Bwalea, who\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Summary:\", generated_summary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:08:18.646065Z",
     "start_time": "2023-12-04T20:08:18.643521Z"
    }
   },
   "id": "51ca1ac49758aee1"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9a8fef32b3e409b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
